

models={\
  "fastspeech2_hifigan": {\
    "1.0": {\
        "defaultVersion": true,\
        "marName": "fastspeech2_hifigan.mar",\
		"default_workers_per_model": 4,\
        "minWorkers": 1,\
        "maxWorkers": 4,\
        "batchSize": 8,\
        "maxBatchDelay": 100,\
        "responseTimeout": 120\
    }\
  }\
}
# bind inference API to all network interfaces with SSL enabled
inference_address=https://0.0.0.0:80
